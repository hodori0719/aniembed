{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e63fdda-0db2-4ea9-8e65-4fca02762410",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests.structures import CaseInsensitiveDict\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "705aac03-c8cd-4bb1-8b69-dcde15a3bdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://myanimelist.net/users.php\"\n",
    "LOOPS = 100\n",
    "LARGE_LOOPS = 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0038403d-4d4c-4f88-b8f1-7eecac50afc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following line initializes the set of users to blank. Only do this once since keeping this uncommented will only sample the users online at runtime\n",
    "# total_loops = 1\n",
    "# userlist = set(())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2ce543cc-a42e-4e79-b2d9-cffc8acffb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We could use tor here to pull more requests simultaneously, but I've found this only gives around 11% more usernames with 10 times the calls\n",
    "for i in range(LOOPS):\n",
    "    page = requests.get(URL)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    results = soup.find(id=\"content\")\n",
    "    usernames = results.find_all(\"a\", itemprop='', string=True)\n",
    "    for user in usernames:\n",
    "        userlist.add(user.text)\n",
    "    time.sleep(1)\n",
    "\n",
    "total_loops += 1\n",
    "\n",
    "# Iterative save to prevent data loss\n",
    "with open(\"usernames/users\" + str(total_loops) + \".txt\", 'w') as outfile:\n",
    "    for username in userlist:\n",
    "        outfile.write(username + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4c1c83dc-d475-4e87-9037-4c6201f089ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note, although we certainly won't use all of these usernames, it's generally a bad idea to filter the data pre-processing since userdata may change wildly between scraping and analysis\n",
    "\n",
    "with open(\"users.txt\", 'w') as outfile:\n",
    "    for username in userlist:\n",
    "        outfile.write(username + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
